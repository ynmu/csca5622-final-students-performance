{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCA 5622 Supervised Learning Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course Number:** CSCA 5622  \n",
    "**Semester:** Summer 2, 2024  \n",
    "**Student Name:** Yuning Mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Project Overview**\n",
    "**Topics and Goals**\n",
    "   - **Project Topic:** \n",
    "     - This project will focus on predicting student performance based on various attributes such as demographic data, family background, and school-related factors.\n",
    "     - **Type of Learning:** Supervised learning.\n",
    "     - **Type of Task:** Classification task (predicting whether a student passes or fails).\n",
    "   - **Goal:** \n",
    "     - The goal of the project is to build a model that can predict student performance to help educators identify students at risk of underperforming and provide timely interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Description**\n",
    "  - **Data Source:** \n",
    "    - The dataset `student-mat.csv` is derived from a public dataset available on the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Student+Performance), specifically in the subject of Mathematics.\n",
    "  - **Description:** \n",
    "    - The dataset includes 396 student records with 30 features related to student achievement in secondary education, which include demographic, social, and school-related features, as well as student grades. The data was collected from two Portuguese schools using school reports and questionnaires.\n",
    "  - **Data Characteristics:** \n",
    "    - **Type:** Multivariate\n",
    "    - **Subject Area:** Social Science\n",
    "    - **Associated Tasks:** Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet reads the dataset `student-mat.csv` and prints the first few rows to give an overview of the data structure.\n",
    "\n",
    "The data contains 395 rows and 33 columns in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
      "\n",
      "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0      4        3      4     1     1      3        6   5   6   6  \n",
      "1      5        3      3     1     1      3        4   5   5   6  \n",
      "2      4        3      2     2     3      3       10   7   8  10  \n",
      "3      3        2      2     1     1      5        2  15  14  15  \n",
      "4      4        3      2     1     2      5        4   6  10  10  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Rows:     395\n",
      "Columns:  33\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/student-mat.csv')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "print(\"Rows:    \", data.shape[0])\n",
    "print(\"Columns: \", data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `data/mapping.py` maps the feature names in the dataset to their actual meanings, making it easier to interpret and understand future visualizations. Below is a sample structure of the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school:\n",
      "    name: School\n",
      "    description: Student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n",
      "    type: Categorical\n",
      "    demographic: None\n",
      "sex:\n",
      "    name: Sex\n",
      "    description: Student's sex (binary: 'F' - female or 'M' - male)\n",
      "    type: Binary\n",
      "    demographic: Sex\n",
      "age:\n",
      "    name: Age\n",
      "    description: Student's age (numeric: from 15 to 22)\n",
      "    type: Integer\n",
      "    demographic: Age\n",
      "... and more\n"
     ]
    }
   ],
   "source": [
    "from data.mapping import feature_mapping\n",
    "\n",
    "SAMPLE_SIZE = 3\n",
    "# Now you can use the feature_mapping dictionary\n",
    "for i, (key, value) in enumerate(feature_mapping.items()):\n",
    "    print(f\"{key}:\")\n",
    "    for k,v in value.items():\n",
    "        print(f\"    {k}: {v}\")\n",
    "    if i + 1 == SAMPLE_SIZE:\n",
    "        break\n",
    "print(\"... and more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Exploratory Data Analysis (EDA) and Data Cleaning**\n",
    "\n",
    "#### a. EDA\n",
    "We can proceed with Exploratory Data Analysis (EDA). We will explore the data visually to understand the distribution of features, correlations between them, and the relationship between features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for Missing or NaN Values**\n",
    "\n",
    "First, it's essential check if the dataset contains any missing or NaN values. Missing values can affect the performance of algorithms and might need to be handled appropriately. The following code checks for missing values in each column of the dataset.\n",
    "There are no missing values or NaN values in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there missing values in any column?\n",
      "No missing values found\n",
      "\n",
      "Are there any NaN values in the dataset?\n",
      "No, there are no NaN values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "\n",
    "print(\"Are there missing values in any column?\")\n",
    "if missing_values.any():\n",
    "    print(\"The following columns have missing values:\")\n",
    "    for column, value in missing_values[missing_values > 0].items():\n",
    "        print(f\"- {column}: {value} missing value(s)\")\n",
    "else:\n",
    "    print(\"No missing values found\")\n",
    "\n",
    "print(\"\\nAre there any NaN values in the dataset?\")\n",
    "if data.isnull().values.any():\n",
    "    nan_columns = data.columns[data.isnull().any()]\n",
    "    print(f\"Yes, there are NaN values in the following columns: {list(nan_columns)}\")\n",
    "else:\n",
    "    print(\"No, there are no NaN values in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for Duplicate Rows**\n",
    "\n",
    "Next, we check for duplicate rows in the dataset. Duplicates can cause bias in the analysis and need to be addressed. The code checks for the number of duplicate rows, and if any are found, it removes them and provides the count of rows before and after the removal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows in the dataset: 0\n",
      "No duplicates found.\n"
     ]
    }
   ],
   "source": [
    "duplicates = data.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows in the dataset: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    data_cleaned = data.drop_duplicates()\n",
    "    print(f\"Number of rows after removing duplicates: {data_cleaned.shape[0]}\")\n",
    "else:\n",
    "    print(\"No duplicates found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Distribution Analysis**\n",
    "\n",
    "Understanding the distribution of each feature is crucial in data analysis, as it helps to identify patterns, outliers, and the overall spread of the data. In this section, we will plot the distribution of each feature in the dataset. For numerical features, we will use histograms, and for categorical features, we will use bar plots.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
